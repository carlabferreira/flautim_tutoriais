{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqLZVV10-uOY"
      },
      "source": [
        "<table style=\"margin: auto; background-color: white;\">\n",
        "    <tr>\n",
        "      <td style=\"background-color: white;\">\n",
        "        <img src='https://drive.google.com/uc?export=view&id=1lgflViz1uefcvVW1iI57haB4M1bKsZtp' alt=\"drawing\" width=\"200\" />\n",
        "      </td>\n",
        "      <td style=\"background-color: white;\">\n",
        "        <img src='https://drive.google.com/uc?export=view&id=1R6PphT9jmd2vikODFPf6cW54QtZ29o2a' alt=\"drawing\" width=\"200\" />\n",
        "      </td>\n",
        "      <td style=\"background-color: white;\">\n",
        "        <img src='https://drive.google.com/uc?export=view&id=1lgflViz1uefcvVW1iI57haB4M1bKsZtp' alt=\"drawing\" width=\"200\" />\n",
        "      </td>\n",
        "      <td style=\"background-color: white;\">\n",
        "        <img src='https://drive.google.com/uc?export=view&id=1R6PphT9jmd2vikODFPf6cW54QtZ29o2a' alt=\"drawing\" width=\"200\" />\n",
        "      </td>\n",
        "      <td style=\"background-color: white;\">\n",
        "        <img src='https://drive.google.com/uc?export=view&id=1lgflViz1uefcvVW1iI57haB4M1bKsZtp' alt=\"drawing\" width=\"200\" />\n",
        "      </td>\n",
        "      <td style=\"background-color: white;\">\n",
        "        <img src='https://drive.google.com/uc?export=view&id=1R6PphT9jmd2vikODFPf6cW54QtZ29o2a' alt=\"drawing\" width=\"200\" />\n",
        "      </td>\n",
        "      <td style=\"background-color: white;\">\n",
        "        <img src='https://drive.google.com/uc?export=view&id=1lgflViz1uefcvVW1iI57haB4M1bKsZtp' alt=\"drawing\" width=\"200\" />\n",
        "      </td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HacTzoG_xm8"
      },
      "source": [
        "# TUTORIAL 4 - FMNIST E SELEÇÃO DE CLIENTES\n",
        "\n",
        "Bem-vindo! Neste tutorial você aprenderá sobre a interface de programação da plataforma **Flautim** e também como montar um experimento simples de classificação usando o dataset [FMNIST](https://huggingface.co/datasets/zalando-datasets/fashion_mnist) com **seleção de clientes**. \n",
        "\n",
        "É recomendado que você já esteja familiarizado com aprendizado federado e utilização da plataforma Flautim, tendo realizado algum dos outros tutoriais previamente.\n",
        "\n",
        "O código desse tutorial pode ser acessado em: [clique aqui](./TUTORIAL_4/).\n",
        "\n",
        "\n",
        "Vamos começar entendendo a interface de programação da **Flautim**, representada na figura abaixo. A **Flautim_api** é uma biblioteca modularizada que facilita a realização de experimentos de aprendizado de máquina, seja convencional/centralizado ou federado.\n",
        "\n",
        "Todo projeto **Flautim** precisa herdar essa biblioteca, que contém submódulos específicos para diferentes tecnologias (por exemplo, submódulos para PyTorch, TensorFlow, etc). Neste tutorial usaremos o submódulo para PyTorch.\n",
        "\n",
        "<div style=\"text-align: center;\"> <table style=\"margin: auto;\"> <tr> <td> <img src='https://drive.google.com/uc?export=view&id=1QOI4jWrwS979xhW_wlGzkPa2bMA-giuc' alt=\"Interface da plataforma Flautim\" width=\"800\" /> </td> </tr> </table> </div>\n",
        "\n",
        "\n",
        "Dentro de cada submódulo existem três componentes principais (classes):\n",
        "\n",
        "**1. Dataset:** é utilizado para representar os dados do experimento. Esta classe pode ser reutilizada em diversos experimentos e com diferentes modelos, sendo o componente mais versátil e reutilizável. Os usuários podem importar os dados de diversas fontes, como arquivos locais ou bases de dados online, desde que a classe Dataset seja herdada.\n",
        "\n",
        "**2. Model:** representa qualquer conjunto de parâmetros treináveis dentro do projeto. Ela permite a aplicação de técnicas de aprendizado de máquina por meio de treinamento desses parâmetros. No caso de PyTorch, a classe herda a nn.Module, que define a estrutura e os parâmetros treináveis do modelo.\n",
        "\n",
        "**3. Experiment:** define o ciclo de treinamento e validação. Existem dois tipos principais de experimentos: o experimento centralizado, que segue o fluxo\n",
        "convencional de aprendizado de máquina, e o experimento federado, adaptado para\n",
        "aprendizado federado. Esta classe inclui duas funções principais, um loop de\n",
        "treinamento e um loop de validação, que realizam a atualização dos parâmetros e\n",
        "cálculo das métricas de custo, respectivamente.\n",
        "\n",
        "Além desses três componentes principais, há também um módulo chamado Common. Este módulo fornece acesso a classes essenciais para o gerenciamento de dados e monitoramento do treinamento.\n",
        "\n",
        "\n",
        "Com essa visão geral, você está pronto para começar montar seus próprios experimentos. Vamos ao passo a passo!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChJrIZCYeTeA"
      },
      "source": [
        "### Passo 1: Criando o dataset que será usado no experimento\n",
        "\n",
        "Um conjunto de dados no Flautim é acessado por um arquivo .py que deve conter uma classe que herda de Dataset.\n",
        "\n",
        "**Exemplo: Implementando a Classe FMNISTDataset**\n",
        "\n",
        "O código abaixo implementa uma classe FMNISTDataset utilizando o dataset FMNIST obtido pelo Hugging Face para resolver um problema de classificação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hz5LGFkzc9CW"
      },
      "outputs": [],
      "source": [
        "from flautim.pytorch.Dataset import Dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import copy\n",
        "from torch.utils.data import DataLoader\n",
        "    \n",
        "class FMNISTDataset(Dataset):\n",
        "\n",
        "    def __init__(self, FM_Normalization, EVAL_Transforms, TRAIN_Transforms, partition, **kwargs):\n",
        "    \n",
        "        name = kwargs.get('name', 'FMNIST')\n",
        "    \n",
        "        super(FMNISTDataset, self).__init__(name, **kwargs)\n",
        "        \n",
        "        self.FM_Normalization = FM_Normalization\n",
        "        self.EVAL_Transforms = EVAL_Transforms\n",
        "        self.TRAIN_Transforms = TRAIN_Transforms\n",
        "        \n",
        "        self.feature_name = kwargs.get(\"feature_name\", 'image')\n",
        "        self.split = kwargs.get(\"split_data\", True)\n",
        "        \n",
        "        if self.split:\n",
        "            partition = partition.train_test_split(test_size=0.2, seed=42)\n",
        "\n",
        "        self.train_partition = partition[\"train\"]\n",
        "        self.test_partition = partition[\"test\"]\n",
        "        \n",
        "    def dataloader(self, validation = False):\n",
        "        tmp = self.validation() if validation else self.train()\n",
        "        return DataLoader(tmp, batch_size = self.batch_size, num_workers = 1)\n",
        "    \n",
        "        \n",
        "    \n",
        "    def apply_train_transforms(self, batch):\n",
        "        \"\"\"Apply transforms to the partition from FederatedDataset.\"\"\"\n",
        "        batch[self.feature_name] = [self.TRAIN_Transforms(img) for img in batch[self.feature_name]]\n",
        "        return batch\n",
        "\n",
        "\n",
        "    def  apply_eval_transforms(self, batch):\n",
        "        \"\"\"Apply transforms to the partition from FederatedDataset.\"\"\"\n",
        "        batch[self.feature_name] = [self.EVAL_Transforms(img) for img in batch[self.feature_name]]\n",
        "        return batch\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "\n",
        "        return self.train_partition.with_transform(self.apply_train_transforms)\n",
        "\n",
        "\n",
        "    def validation(self):\n",
        "        \n",
        "        return self.test_partition.with_transform(self.apply_eval_transforms)\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EbqONNwmV3X"
      },
      "source": [
        "### Passo 2: Criando o modelo que será usado no experimento\n",
        "\n",
        "Agora, vamos criar a classe que implementa o modelo. Essa classe deve herdar da classe Model.\n",
        "\n",
        "\n",
        "**Exemplo: Implementando a Classe PoCModel_2HiddenLayers**\n",
        "\n",
        "A classe ```PoCModel_2HiddenLayers``` implementa uma rede neural convolucional baseada na rede proposta do Paper Power-Of-Choice, com as seguintes camadas:\n",
        "* Pre-processamento (flatten): a entrada (assumidamente um lote de imagens 28x28) é achatada em um vetor de 784 características\n",
        "* Uma camada oculta totalmente conectada, com entrada de 784 neurônios e saída de 256 neurônios. Ativação ReLU.\n",
        "* Uma camada oculta totalmente conectada, com entrada de 256 neurônios e saída de 128 neurônios. Ativação ReLU.\n",
        "* Uma camada de saída totalmente conectada com número de neurônios igual ao número de classes do problema.\n",
        "\n",
        "Essa classe pode ser incluída, por exemplo, em um arquivo MNISPoCModel_2HiddenLayers.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X51g0zkU-ikV"
      },
      "outputs": [],
      "source": [
        "from flautim.pytorch.Model import Model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class PoCModel_2HiddenLayers(Model):\n",
        "    \"\"\"\n",
        "    MLP Profundo com DUAS CAMADAS OCULTAS para FMNIST (784 -> 256 -> 128 -> 10)\n",
        "    Modelo como descrito no paper de referência de Power of Choice\n",
        "    \"\"\"\n",
        "    def __init__(self, context, num_classes: int, **kwargs) -> None:\n",
        "        super(PoCModel_2HiddenLayers, self).__init__(context, name = \"2HiddenLayersNN\", version = 1, id = 1, **kwargs)\n",
        "\n",
        "        self.hidden1 = nn.Linear(784, 256)\n",
        "        self.hidden2 = nn.Linear(256, 128)\n",
        "        \n",
        "        self.output_layer = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1) # Flatten da imagem (28x28 -> 784)\n",
        "        \n",
        "        x = F.relu(self.hidden1(x))\n",
        "        x = F.relu(self.hidden2(x))\n",
        "        \n",
        "        x = self.output_layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TF_5DkrmXwb"
      },
      "source": [
        "### Passo 3: Criando o experimento\n",
        "\n",
        "Por fim, será criado o experimento, isto é, uma classe que implementa os loops de treinamento e validação do modelo PoCModel_2HiddenLayers no dataset FMNISTDataset. Para isso, precisamos criar dois arquivos .py, o run.py (que deve ter obrigatoriamente esse nome) e o .py responsável por implementar o experimento, descritos a seguir:\n",
        "\n",
        "**1. Arquivo run.py:**\n",
        "\n",
        "* Esse arquivo é o ponto de entrada de todo experimento Flautim, pois é ele\n",
        "que deve iniciar a classe do experimento e também um modelo e um Dataset.\n",
        "\n",
        "**2. Arquivo .py do experimento:**\n",
        "\n",
        "* Esse arquivo deve conter uma classe que implemente os métodos de treinamento (training_loop) e validação (evaluation_loop) do modelo. Essa classe deve herdar da classe Experiment.\n",
        "\n",
        "Esse tutorial cobrirá dois tipos de experimentos, um experimento centralizado e outro descentralizado. Portanto, o passo 3 será dividido entre esses dois cenários."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Seleção de Clientes**\n",
        "Ao considerar o funcionamento do aprendizado federado, onde os modelos locais dos clientes são enviados para o servidor central que utilizará uma estratégia de agregação (como FedAvg) para treinar o modelo global, a participação dos clientes é um fator importante para o desempenho do modelo. \n",
        "\n",
        "Ao utilizarmos, por exemplo, o [framework flower](https://flower.ai/docs/framework/#) sem definir uma seleção específica, a quantidade percentual de clientes definida no ```fraction_fit``` será usada para escolher **aleatoriamente** entre os clientes disponíveis na rodada. \n",
        "Essa entre os clientes é feita pela  ``` class SimpleClientManager (ClientManager) ```\n",
        "em ``` (207) sampled_cids = random.sample(available_cids, num_clients) ``` \n",
        "e pode ser estudada em https://github.com/adap/flower/blob/main/framework/py/flwr/server/client_manager.py.\n",
        "\n",
        "##### Definindo uma nova estratégia\n",
        "\n",
        "Na literatura diversos autores já abordaram o tema, como [Cho et al.](https://proceedings.mlr.press/v151/jee-cho22a/jee-cho22a.pdf) que propõem Power-Of-Choice (POC), uma estrutura de seleção de clientes que direciona a seleção de clientes para clientes com maior perda local, permitindo uma convergência mais rápida e aumentamdo a eficiência da comunicação.\n",
        "\n",
        "Para definirmos uma nova estratégia de seleção de clientes, usualmente estamos interresados em escolher de acordo com uma informação do treinamento atual (por exemplo a _loss_ para POC). Essas informações só estão disponíveis durante a etapa de treinamento (onde o metodo _fit_ é chamado), anterior a agregação do servidor. Assim, a solução adotada é definir uma nova estratégia extendendo uma existente (como FedAvg) e modificando o método ```configure_fit```.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEABgvWrGxNN"
      },
      "source": [
        "#### Passo 3.1: Experimento federado\n",
        "**Implementando a Classe FMNISTExperiment**\n",
        "\n",
        "No código abaixo, criamos a classe FMNISTExperiment no modo federado com seus métodos training_loop e evaluation_loop para treinar e testar a rede neural. Esses métodos retornam o valor da função de perda e a acurácia de treinamento e de validação.\n",
        "\n",
        "Repare que o método ```fit``` é redefinido para ter um tratamento extra da _loss_ local a ser utilizado na estratégia POC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCOysvCsG5qL"
      },
      "outputs": [],
      "source": [
        "from flautim.pytorch.federated.Experiment import Experiment\n",
        "import flautim as fl\n",
        "import flautim.metrics as flm\n",
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "\n",
        "from collections import OrderedDict\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from math import inf\n",
        "\n",
        "from random import random\n",
        "\n",
        "# Two auxhiliary functions to set and extract parameters of a model\n",
        "def set_params(model, parameters):\n",
        "    \"\"\"Replace model parameters with those passed as `parameters`.\"\"\"\n",
        "\n",
        "    params_dict = zip(model.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.from_numpy(v) for k, v in params_dict})\n",
        "    model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "\n",
        "def get_params(model):\n",
        "    \"\"\"Extract model parameters as a list of NumPy arrays.\"\"\"\n",
        "    return [val.cpu().numpy() for _, val in model.state_dict().items()]\n",
        "\n",
        "class PoCExperimentFMNIST(Experiment):\n",
        "    \"\"\"\n",
        "    Experimento baseline para o MNIST\n",
        "    Baseado no tutorial do flautim e definições prévias.\n",
        "    Utiliza o modelo BaselineModelMNIST e o dataset MNISTDataset (do tutorial).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, dataset, context, **kwargs):\n",
        "        super(PoCExperimentFMNIST, self).__init__(model, dataset, context, **kwargs)\n",
        "        \n",
        "        self.criterion = torch.nn.CrossEntropyLoss()\n",
        "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=0.01, momentum=0.9)\n",
        "        self.epochs = kwargs.get('epochs', 1)\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.last_loss = inf\n",
        "        self.last_participation_round = 0\n",
        "        self.model = model\n",
        "        self.data_size = len(dataset.train_partition) # Store the size of the local training data\n",
        "\n",
        "    # --------------------------------\n",
        "    # Ref: https://discuss.flower.ai/t/custom-client-selection-strategy/63\n",
        "    def fit(self, parameters, config):\n",
        "        set_params(self.model, parameters)\n",
        "        epochs = config.get(\"epochs\", self.epochs) # Get the number of epochs from config\n",
        "        if epochs == -1:\n",
        "            return parameters, 0, {\"data_size\": self.data_size}  # Just return client's data size\n",
        "\n",
        "        if epochs == 0:\n",
        "            # Estimate local loss without training the model\n",
        "            local_loss, _ = self.validation_loop(self.dataset.dataloader(validation=True))\n",
        "            local_loss += np.random.uniform(low=1e-10, high=1e-9) # Make sure that potential ties are broken at random\n",
        "            return parameters, 0, {\"local_loss\": local_loss}  # Return the estimated local loss without updating the parameters\n",
        "\n",
        "        # Train the model and return the updated parameters\n",
        "        # self.fit(self.x_train, self.y_train, validation_data=(self.x_test, self.y_test), epochs = self.epochs, verbose=0)\n",
        "        loss, metrics = self.training_loop(self.dataset.dataloader())\n",
        "        return get_params(self.model), self.data_size, metrics\n",
        "    # --------------------------------\n",
        "\n",
        "    def training_loop(self, data_loader):\n",
        "        \"\"\"This method trains the model using the parameters sent by the\n",
        "        server on the dataset of this client. At then end, the parameters\n",
        "        of the locally trained model are communicated back to the server\"\"\"\n",
        "        \n",
        "        self.model.to(self.device)\n",
        "        self.model.train()\n",
        "        \n",
        "        correct, running_loss = 0.0, 0.0\n",
        "\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        self.model.to(self.device)\n",
        "        self.model.train()\n",
        "        for batch in data_loader:\n",
        "            images, labels = batch[\"image\"].to(self.device), batch[\"label\"].to(self.device)\n",
        "            self.optimizer.zero_grad()\n",
        "        \n",
        "            outputs = self.model(images.to(self.device))\n",
        "            # todo alterar caso FedProx!\n",
        "            loss = criterion(self.model(images), labels)\n",
        "            \n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            correct += (torch.max(outputs, 1)[1].cpu() == labels.cpu()).sum().item()\n",
        "\n",
        "        accuracy = correct / len(data_loader.dataset)    \n",
        "        avg_trainloss = running_loss / len(data_loader)\n",
        "        \n",
        "        self.last_loss = avg_trainloss           \n",
        "        \n",
        "        return float(avg_trainloss), {'ACCURACY': accuracy}\n",
        "\n",
        "\n",
        "    def validation_loop(self, data_loader):\n",
        "        # Usa função evaluate do colab como base\n",
        "        \"\"\"Evaluate the model sent by the server on this client's\n",
        "        local validation set. Then return performance metrics.\"\"\"\n",
        "\n",
        "        all_predictions = []\n",
        "        all_labels = []\n",
        "\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        correct, loss = 0, 0.0\n",
        "\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in data_loader:\n",
        "                images, labels = batch[\"image\"].to(self.device), batch[\"label\"].to(self.device)\n",
        "                outputs = self.model(images)\n",
        "                loss += criterion(outputs, labels).item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "                all_predictions.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        accuracy = correct / len(data_loader.dataset)\n",
        "        f1 = f1_score(all_labels, all_predictions, average='macro')\n",
        "\n",
        "        return float(loss), {\"accuracy\": accuracy, \"f1\": f1}\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QO279cKP1BNb"
      },
      "source": [
        "**Implementando o run.py para realização de um experimento federado**\n",
        "\n",
        "**1. Upload do Conjunto de Dados:**\n",
        "\n",
        "* *Arquivo Local:* Se o seu conjunto de dados for um arquivo (por exemplo, CSV, NPZ, etc.), faça o upload para a plataforma e carregue-o usando o caminho ./data/nomedoarquivo.\n",
        "\n",
        "* *URL:* Se o conjunto de dados estiver disponível em uma URL, inclua a URL no seu código e carregue-o diretamente.\n",
        "\n",
        "**2. Separação dos dados por cliente:**\n",
        "\n",
        "* Para simular 4 clientes, divida os dados em 4 partes.\n",
        "\n",
        "**3. Crie uma instância para FMNISTDataset, PoCModel_2HiddenLayers, PoCExperimentFMNIST.**\n",
        "\n",
        "**4. Execute as funções:**\n",
        "* ***generate_server_fn:*** Cria a estratégia para o aprendizado federado\n",
        "* ***generate_client_fn:*** Gera o modelo e o dataset de cada cliente.\n",
        "* ***evaluate_fn:*** Avalia o modelo global usando o dataset de um dos clientes.\n",
        "* ***run_federated:*** Executa o experimento federado.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Modificações para seleção de clientes**\n",
        "É necessário definir uma classe que herde de uma _strategy_ para ser utilizada ao criar o servidor. \n",
        "\n",
        "No exemplo abaixo a ``class MyStrategy(FedAvg)`` poderia ser definida em outro arquivo, por exemplo MyStrategy.py, mas por simplicidade foi declarada no run para evitar imports.\n",
        "\n",
        "Ao definirmos o servidor utilizamos ``strategy = MyStrategy(...)`` e todo o tratamento da seleção de cliente será feito pela mesma. Nesse exemplo o funcionamento base é:\n",
        "1. Obtém o número de clientes disponíveis\n",
        "2. Calcula a probabilidade de escolher determinado cliente baseado no tamanho do dataset\n",
        "3. Seleciona os d (30) clientes com maiores probabilidades como candidatos\n",
        "4. Dentre estes candidatos, solicita os valores de perdas locais\n",
        "5. Selecione os m (min_fit_clients = 3) com maiores perdas locais e informa para o ClientManager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25KUsCbg07mp"
      },
      "outputs": [],
      "source": [
        "from flautim.pytorch.common import run_federated, weighted_average\n",
        "from flautim.pytorch import Model, Dataset\n",
        "from flautim.pytorch.federated import Experiment\n",
        "import FMNISTDataset, PoCModel_2HiddenLayers, PoCExperimentFMNIST # Alterado!\n",
        "from PoCExperimentFMNIST import get_params # Alterado!\n",
        "import flautim as fl\n",
        "from flwr_datasets import FederatedDataset\n",
        "from flwr_datasets.partitioner import DirichletPartitioner\n",
        "from flwr.common import Context, ndarrays_to_parameters\n",
        "import flwr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from flwr.server import ServerConfig, ServerAppComponents\n",
        "from datasets import load_dataset\n",
        "\n",
        "from random import random\n",
        "from flwr.server.client_manager import ClientManager\n",
        "from flwr.common import Parameters, FitIns\n",
        "from flwr.server.strategy import FedAvg\n",
        "from flwr.server.client_proxy import ClientProxy\n",
        "from time import sleep\n",
        "\n",
        "NUM_PARTITIONS = 100 # Alterado! Numero de clientes totais e numero de partições de dados\n",
        "DATASET = \"ylecun/mnist\" # Alterado!\n",
        "\n",
        "from torchvision.transforms import (\n",
        "    Compose,\n",
        "    Normalize,\n",
        "    RandomCrop,\n",
        "    RandomHorizontalFlip,\n",
        "    ToTensor,\n",
        ")\n",
        "\n",
        "\n",
        "FM_NORMALIZATION = ((0.1307,), (0.3081,))\n",
        "EVAL_TRANSFORMS = Compose([ToTensor(), Normalize(*FM_NORMALIZATION)])\n",
        "TRAIN_TRANSFORMS = Compose(\n",
        "    [\n",
        "        RandomCrop(28, padding=4),\n",
        "        RandomHorizontalFlip(),\n",
        "        ToTensor(),\n",
        "        Normalize(*FM_NORMALIZATION),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# Ref:https://discuss.flower.ai/t/custom-client-selection-strategy/63\n",
        "class MyStrategy(FedAvg):\n",
        "    \"\"\"Behaves just like FedAvg but with a modified sampling.\n",
        "    \"\"\"\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.p = [] # probabilities for each client based on data size?\n",
        "        self.d = 30 # number of candidate clients to consider each round\n",
        "        self.m = self.min_fit_clients # number of clients to select each round\n",
        "        # self.prev_clients = [] # store client proxies from previous round\n",
        "    \n",
        "    def configure_fit(\n",
        "        self, server_round: int, parameters: Parameters, client_manager = ClientManager # client_manager alterado!\n",
        "        ) -> list[tuple[ClientProxy, FitIns]]: \n",
        "        \"\"\"Configure the next round of training.\"\"\"\n",
        "        # Get list with all the available clients (K clients)\n",
        "        available_clients = list(client_manager.clients.values())\n",
        "\n",
        "        print(f\"Round {server_round} - Available clients: {[client.cid for client in available_clients]}\")\n",
        "        \n",
        "        if self.p == []:\n",
        "            data_sizes = {\n",
        "                client.cid: client.fit(\n",
        "                    FitIns(parameters, {\"epochs\": -1}), \n",
        "                    timeout=60, \n",
        "                    group_id=str(client.cid)\n",
        "                ).metrics.get(\"data_size\", 0)\n",
        "                for client in available_clients\n",
        "            }\n",
        "            \n",
        "            for key, value in data_sizes.items():\n",
        "                print(f\"Cliente {key} tem {value} data_size.\")\n",
        "\n",
        "            # Compute selection probabilities based on data size\n",
        "            total_size = sum(data_sizes.values())\n",
        "            self.p = [size / total_size for size in data_sizes.values()]\n",
        "\n",
        "            for i in self.p:\n",
        "                print(f\"p = {i}\")\n",
        "\n",
        "            p_np = np.array(self.p)\n",
        "            soma_real = p_np.sum()\n",
        "            \n",
        "            p_np /= soma_real # Normaliza a maior parte do array\n",
        "            last_index = len(p_np) - 1\n",
        "            desvio = 1.0 - p_np[:-1].sum()\n",
        "            p_np[last_index] = desvio # Força o último elemento a compensar o desvio\n",
        "            self.p = p_np.tolist()\n",
        "\n",
        "        # Sample d clients with a probability proportional to their data size\n",
        "        candidate_clients = np.random.choice(\n",
        "            available_clients,\n",
        "            size=min(self.d, len(available_clients)),\n",
        "            p=self.p,\n",
        "            replace=False\n",
        "        )\n",
        "\n",
        "        # Request the candidate clients to compute their local losses and return them to the server\n",
        "        local_losses = {\n",
        "            client.cid: client.fit(\n",
        "                FitIns(parameters, {\"epochs\": 0}), \n",
        "                timeout=4,\n",
        "                group_id=str(client.cid) #? Added to fix the error\n",
        "            ).metrics.get('local_loss', float('inf'))\n",
        "            for client in candidate_clients\n",
        "        }\n",
        "\n",
        "        # Select the top m clients with the highest local losses\n",
        "        selected_clients_cids = sorted(local_losses, key=local_losses.get, reverse=True)[:self.m]\n",
        "        selected_clients = []\n",
        "        selected_clients.append([key for key in selected_clients_cids])\n",
        "\n",
        "        # Return the selected clients with the FitIns objects\n",
        "        return [(client_manager.clients.get(cid), FitIns(parameters, {})) for cid in selected_clients_cids]\n",
        "        \n",
        "\n",
        "# -------------------------------\n",
        "\n",
        "\n",
        "def fit_config(server_round: int):\n",
        "    \"\"\"Return training configuration dict for each round.\n",
        "\n",
        "    Perform two rounds of training with one local epoch, increase to two local\n",
        "    epochs afterwards.\n",
        "    \"\"\"\n",
        "    config = {\n",
        "        \"server_round\": server_round,  # The current round of federated learning\n",
        "    }\n",
        "    return config\n",
        "\n",
        "\n",
        "\n",
        "def generate_server_fn(context, eval_fn, **kwargs):\n",
        "\n",
        "    def create_server_fn(context_flwr:  Context):\n",
        "\n",
        "        net = PoCModel_2HiddenLayers.PoCModel_2HiddenLayers(context, num_classes = 10, suffix = 0)\n",
        "        ndarrays = get_params(net)\n",
        "        global_model_init = ndarrays_to_parameters(ndarrays)\n",
        "\n",
        "        strategy = MyStrategy(\n",
        "                          evaluate_fn=eval_fn,\n",
        "                          on_fit_config_fn = fit_config,\n",
        "                          on_evaluate_config_fn = fit_config,\n",
        "                          evaluate_metrics_aggregation_fn=weighted_average,  # callback defined earlier\n",
        "                          initial_parameters=global_model_init,  # initialised global model,\n",
        "                          fraction_fit=0.03,\n",
        "                          min_fit_clients=3,\n",
        "                        )\n",
        "        num_rounds = 100\n",
        "        config = ServerConfig(num_rounds=num_rounds)\n",
        "\n",
        "        return ServerAppComponents(config=config, strategy=strategy)\n",
        "    return create_server_fn\n",
        "\n",
        "def generate_client_fn(context):\n",
        "\n",
        "    def create_client_fn(context_flwr:  Context):\n",
        "\n",
        "        global fds\n",
        "\n",
        "        cid = int(context_flwr.node_config[\"partition-id\"])\n",
        "\n",
        "        partition = fds.load_partition(cid)\n",
        "\n",
        "        model = PoCModel_2HiddenLayers.PoCModel_2HiddenLayers(context, num_classes = 10, suffix = cid)\n",
        "\n",
        "        dataset = FMNISTDataset.FMNISTDataset(FM_NORMALIZATION, EVAL_TRANSFORMS, TRAIN_TRANSFORMS, partition, batch_size = 32, shuffle = False, num_workers = 0)\n",
        "\n",
        "        return PoCExperimentFMNIST.PoCExperimentFMNIST(model, dataset,  context).to_client()\n",
        "\n",
        "    return create_client_fn\n",
        "\n",
        "\n",
        "def evaluate_fn(context):\n",
        "    def fn(server_round, parameters, config):\n",
        "        \"\"\"This function is executed by the strategy it will instantiate\n",
        "        a model and replace its parameters with those from the global model.\n",
        "        The, the model will be evaluate on the test set (recall this is the\n",
        "        whole MNIST test set).\"\"\"\n",
        "\n",
        "        global FM_NORMALIZATION, EVAL_TRANSFORMS, TRAIN_TRANSFORMS, DATASET\n",
        "        global fds\n",
        "\n",
        "        model = PoCModel_2HiddenLayers.PoCModel_2HiddenLayers(context, num_classes = 10, suffix = \"FL-Global\")\n",
        "        model.set_parameters(parameters)\n",
        "\n",
        "        partition = fds.load_partition(0)\n",
        "\n",
        "        dataset = FMNISTDataset.FMNISTDataset(FM_NORMALIZATION, EVAL_TRANSFORMS, TRAIN_TRANSFORMS, partition, batch_size = 32, shuffle = False, num_workers = 0)\n",
        "        dataset.test_partition = load_dataset(DATASET)[\"test\"]\n",
        "\n",
        "        experiment = PoCExperimentFMNIST.PoCExperimentFMNIST(model, dataset, context)\n",
        "\n",
        "        config[\"server_round\"] = server_round\n",
        "\n",
        "        loss, _, return_dic = experiment.evaluate(parameters, config)\n",
        "\n",
        "        return loss, return_dic\n",
        "\n",
        "    return fn\n",
        "\n",
        "partitioner = DirichletPartitioner(\n",
        "            num_partitions=NUM_PARTITIONS,\n",
        "            partition_by=\"label\",\n",
        "            alpha=0.3,\n",
        "            seed=42,\n",
        "        )\n",
        "fds = FederatedDataset(\n",
        "            dataset=DATASET,\n",
        "            partitioners={\"train\": partitioner},\n",
        "        )\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    context = fl.init()\n",
        "\n",
        "    fl.log(f\"Flautim inicializado!!!\")\n",
        "\n",
        "\n",
        "    client_fn_callback = generate_client_fn(context)\n",
        "    evaluate_fn_callback = evaluate_fn(context)\n",
        "    server_fn_callback = generate_server_fn(context, eval_fn = evaluate_fn_callback)\n",
        "\n",
        "    fl.log(f\"Experimento criado!!!\")\n",
        "\n",
        "    run_federated(client_fn_callback, server_fn_callback, num_clients = NUM_PARTITIONS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Referências\n",
        "- [1] (Flautim tutoriais) Demais Tutorias disponíveis [aqui](https://github.com/FutureLab-DCC/flautim_tutoriais/tree/main)\n",
        "\n",
        "- [2] (Artigo) Jee Cho, Y., Wang, J., and Joshi, G. (2022). Towards understanding biased client selection in federated learning. In Camps-Valls, G., Ruiz, F. J. R., and Valera, I., editors, Proceedings of The 25th International Conference on Artificial Intelligence and Statistics, volume 151 of Proceedings of Machine Learning Research, pages 10351–10375. PMLR.\n",
        "\n",
        "- [3] (Discussão no Fórum do Flower - How do I write a custom client selection protocol? & \"RepeatHalfSamplingFedAvg\") https://discuss.flower.ai/t/how-do-i-write-a-custom-client-selection-protocol/74\n",
        "\n",
        "- [4] (Discussão no Fórum do Flower - Custom client selection strategy) https://discuss.flower.ai/t/custom-client-selection-strategy/63\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<p style=\"text-align: center;\">\n",
        "✨ Disponibilizado por Carla B. Ferreira, aluna de IC do FutureLab, em 2025. ✨\n",
        "</p>\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
